{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nav_menu": {
      "height": "252px",
      "width": "333px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Furg - ECD 06b - Machine Learning I - Ensemble Learning",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcpiscator/01T2021/blob/main/Furg_ECD_06b_Machine_Learning_I_Ensemble_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFWQA_iCZ5Wx"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning I - Ensemble Learning\n",
        "### Prof. Marcelo Malheiros\n",
        "\n",
        "Código adaptado de Aurélien Geron (licença Apache-2.0)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc51aKVSZ5W-"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_:\n",
        "\n",
        "- NumPy: suporte a vetores, matrizes e operações de Álgebra Linear\n",
        "- Matplotlib: biblioteca de visualização de dados\n",
        "- Scikit-Learn: biblioteca com algoritmos de Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIe80YnVZ5W_"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zCoi4LWZ5XA"
      },
      "source": [
        "# Classificação _ensemble_ usando _hard voting_\n",
        "\n",
        "Neste exemplo usamos novamente o _dataset_ sintético `moons`. E também usamos a função `train_test_split` para dividir aleatoriamente este conjunto em 75% de instâncias para treino e 25% para teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P6IZnmQZ5XB"
      },
      "source": [
        "# criação dos dados\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp7-8AiTZ5XC"
      },
      "source": [
        "# separação em conjuntos de treino e de teste\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZTMOiETZ5XD"
      },
      "source": [
        "Aqui vamos criar três classificadores usando algoritmos distintos, que em seguida serão combinados em um _ensemble_.\n",
        "\n",
        "O classificador de votação é construído usando um `VotingClassifier`. Este classificador _ensemble_ funciona da mesma forma que um classificador normal, podendo então ser treinado e gerando previsões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK72cwoEZ5XD"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression(random_state=42, solver='lbfgs')\n",
        "rnd_clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "svc_clf = SVC(random_state=42, probability=True, gamma='scale')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CShdUcshZ5XE"
      },
      "source": [
        "# criação do classificador por hard voting\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[('log', log_clf), ('rnd', rnd_clf), ('svc', svc_clf)], voting='hard')\n",
        "\n",
        "# treinamento\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTAZ07PbZ5XH"
      },
      "source": [
        "Abaixo vamos fazer uma comparação medindo a **acurácia** entre cada um dos três classificadores simples e o classificador _ensemble_ (usando os dados de **teste**, neste caso):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtDN_JneZ5XI"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svc_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(accuracy_score(y_test, y_pred), clf.__class__.__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdR99cd2Z5XK"
      },
      "source": [
        "# Classificação _ensemble_ usando _soft voting_\n",
        "\n",
        "Os mesmos algoritmos anteriores são usados, pois todos eles geram probabilidades (note que definimos o parâmetro `probability=True` no algoritmo `SVC` explicitamente para ter tais probabilidades).\n",
        "\n",
        "Então é possível indicar para o `VotingClassifier` que as predições devem ser ponderadas pelas suas respectivas probabilidades, para então gerar a predição final."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH-oOP7IZ5XL"
      },
      "source": [
        "# criação do classificador por soft voting\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[('log', log_clf), ('rnd', rnd_clf), ('svc', svc_clf)], voting='soft')\n",
        "\n",
        "# treinamento\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G32EngvRZ5XM"
      },
      "source": [
        "Novamente fazemos uma comparação medindo a **acurácia** entre cada um dos três classificadores simples e o classificador _ensemble_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcZdrJ00Z5XM"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svc_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(accuracy_score(y_test, y_pred), clf.__class__.__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpW5EpppZ5XN"
      },
      "source": [
        "# Classificação _ensemble_ usando _bagging_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8H1C7enZ5XN"
      },
      "source": [
        "Aqui vamos usar um conjunto de modelos `DecisionTreeClassifier`, do tipo árvore de decisão, combinados em um _ensemble_ usando a técnica de _bagging_.\n",
        "\n",
        "Note os parâmetros de criação do modelo usando `BaggingClassifier`:\n",
        "\n",
        "- `n_estimators=500`: cria 500 modelos do tipo árvore de decisão\n",
        "- `max_samples=100`: cada modelo é treinado com 100 instâncias selecionadas aleatoriamente\n",
        "- `bootstrap=True`: faz uso de _bagging_ (repetindo instâncias); _pasting_ teria esse parâmetro como `False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DF8LwdpZ5XN"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# criação do ensemble\n",
        "\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), random_state=42,\n",
        "                            n_estimators=500, max_samples=100, bootstrap=True)\n",
        "\n",
        "# treinamento\n",
        "bag_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9VvZpFaZ5XO"
      },
      "source": [
        "Aqui podemos comparar o resultado de um classificador único, baseado em árvore de descisão, com o _ensemble_ criado com 500 árvores distintas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqRXE1w6Z5XO"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# acurácia para modelo simples de árvore de decisão\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_tree), tree_clf.__class__.__name__)\n",
        "\n",
        "# acurácia para modelo ensemble\n",
        "\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred), bag_clf.__class__.__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wFuton1Z5XP"
      },
      "source": [
        "Vale a pena também visualizar as fronteiras de decisão induzidas tanto pelo classificador simples como pelo _ensemble_, que é feito pelo código abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dMYndZbZ5XP"
      },
      "source": [
        "# não se preocupe com este código\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.45, -1, 1.5], alpha=0.5, contour=True):\n",
        "    x1s = np.linspace(axes[0], axes[1], 100)\n",
        "    x2s = np.linspace(axes[2], axes[3], 100)\n",
        "    x1, x2 = np.meshgrid(x1s, x2s)\n",
        "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
        "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
        "    cmap1 = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=cmap1)\n",
        "    if contour:\n",
        "        cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
        "        plt.contour(x1, x2, y_pred, cmap=cmap2, alpha=0.8)\n",
        "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], 'yo', alpha=alpha)\n",
        "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], 'bs', alpha=alpha)\n",
        "    plt.axis(axes)\n",
        "    plt.xlabel(r'$x_1$', fontsize=18)\n",
        "    plt.ylabel(r'$x_2$', fontsize=18, rotation=0)\n",
        "\n",
        "fix, axes = plt.subplots(ncols=2, figsize=(14,4), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_decision_boundary(tree_clf, X, y)\n",
        "plt.title('árvore de decisão', fontsize=14)\n",
        "plt.sca(axes[1])\n",
        "plot_decision_boundary(bag_clf, X, y)\n",
        "plt.title('árvores de decisão com bagging', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAEoI-axZ5XQ"
      },
      "source": [
        "# Florestas aleatórias\n",
        "\n",
        "Em geral o algoritmo `RandomForestClassifier` tem todos os hiperparâmetros de um `DecisionTreeClassifier` (para controlar como as árvores crescem) e mais todos os hiperparâmetros de um `BaggingClassifier` (para controlar o uso dos dados de treinamento).\n",
        "\n",
        "Adicionalmente, o algoritmo `RandomForestClassifier` introduz aleatoriedade extra ao criar árvores; em vez de procurar a melhor _feature_ ao dividir um nodo, este procura a melhor _feature_ entre um subconjunto aleatório de _features_.\n",
        "\n",
        "Isso resulta em uma maior diversidade de árvores, geralmente resultando em um modelo _ensemble_ ainda melhor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40QHIe4mZ5XR"
      },
      "source": [
        "# criação, treinamento e predição\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(random_state=42, n_estimators=500, max_leaf_nodes=16)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIwBz39Z1Iin"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# acurácia para modelo simples de árvore de decisão\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred_tree), tree_clf.__class__.__name__)\n",
        "\n",
        "# acurácia para modelo de floresta aleatória\n",
        "\n",
        "y_pred = rnd_clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred), rnd_clf.__class__.__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6NsHH3pZ5XR"
      },
      "source": [
        "Para visualizar o funcionamento de uma floresta aleatória, podemos sobrepor as fronteiras de decisão de **n** árvores de decisão, treinadas individualmente.\n",
        "\n",
        "Quanto mais árvores são mostradas (cada uma parcialmente transparente), mais evidente fica a **fronteira combinada de decisão** deste algoritmo _ensemble_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly-PZ3HyZ5XS"
      },
      "source": [
        "# não se preocupe com os detalhes deste código\n",
        "\n",
        "n = 1\n",
        "plt.figure(figsize=(12, 5))\n",
        "for i in range(n):\n",
        "    tree_clf = DecisionTreeClassifier(random_state=42 + i, max_leaf_nodes=16)\n",
        "    indices_with_replacement = np.random.randint(0, len(X_train), len(X_train))\n",
        "    tree_clf.fit(X[indices_with_replacement], y[indices_with_replacement])\n",
        "    plot_decision_boundary(tree_clf, X, y, axes=[-1.5, 2.45, -1, 1.5], alpha=0.02, contour=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB2b4dQiZ5XS"
      },
      "source": [
        "# Importância das _features_\n",
        "\n",
        "Outra grande utilidade de florestas aleatórias é que estas tornam mais fácil medir a **importância relativa** de cada _feature_.\n",
        "\n",
        "A importância de uma _feature_ pode ser medida observando quantos nodos das árvores da floresta usam essa _feature_ como critério de decisão. Mais precisamente, se calcula uma média ponderada, em que o peso de cada nodo é igual ao número de instâncias que estão associadas ao mesmo.\n",
        "\n",
        "A biblioteca `Scikit-Learn` calcula essa pontuação automaticamente para cada _feature_ após o treinamento. Esses resultados são normalizados para que a soma de todas as importâncias seja igual a 1.\n",
        "\n",
        "Podemos acessar o resultado usando `.feature_importances_`.\n",
        "\n",
        "O código a seguir treina um algoritmo `RandomForestClassifier` no conjunto de dados IRIS, exibindo a importância de cada _feature_.\n",
        "\n",
        "No caso, as características mais importantes são o comprimento da pétala (44%) e a largura (42%), enquanto o comprimento e a largura da sépala são pouco importantes em comparação (11% e 2%, respectivamente)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbLFa1u0Z5XT"
      },
      "source": [
        "# leitura dos dados, criação e treinamento do modelo\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
        "rnd_clf.fit(iris['data'], iris['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHJd26NFZ5XT"
      },
      "source": [
        "# lista com as importâncias das features\n",
        "rnd_clf.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vNJWoofZ5XU"
      },
      "source": [
        "# features listadas por ordem crescente de importância\n",
        "for score, name in sorted(zip(rnd_clf.feature_importances_, iris['feature_names'])):\n",
        "    print('{:06.2%}'.format(score), name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}