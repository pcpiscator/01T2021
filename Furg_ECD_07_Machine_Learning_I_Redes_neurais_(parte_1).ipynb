{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Furg - ECD 07 - Machine Learning I - Redes neurais (parte 1)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcpiscator/01T2021/blob/main/Furg_ECD_07_Machine_Learning_I_Redes_neurais_(parte_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg9PW0XaFzDy"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning I - Redes Neurais (parte 1)\n",
        "### Prof. Marcelo Malheiros\n",
        "\n",
        "Código adaptado de Aurélien Geron (licença Apache-2.0)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAMVIFQBFzD-"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_:\n",
        "\n",
        "- NumPy: suporte a vetores, matrizes e operações de Álgebra Linear\n",
        "- Matplotlib: biblioteca de visualização de dados\n",
        "- Pandas: pacote estatístico e de manipulação de DataFrames\n",
        "- Scikit-Learn: biblioteca com algoritmos de Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd1JPPl0FzD_"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaxEHSUXFzEB"
      },
      "source": [
        "Este _notebook_, em particular, utiliza a biblioteca Keras para definir e treinar redes neurais. Aqui utilizamos a versão **integrada** de Keras, que já vem como parte da biblioteca mais geral TensorFlow.\n",
        "\n",
        "Em geral é mais fácil usar a versão integrada de Keras, pois esta está pronta para usar a Tensorflow, sem risco de incompatibilidade.\n",
        "\n",
        "Ambas já fazem parte do ambiente Colaboratory.\n",
        "\n",
        "**Atenção:** para quem utiliza o ambiente Jupyter, é preciso primeiro instalar o pacote `tensorflow`. Na linha de comando isso pode ser feito assim:\n",
        "\n",
        "    conda install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqhhFG1cFzEC",
        "outputId": "65147f3c-97dc-4f17-93bb-a8fe7015d46f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print('tensorflow:      versão', tf.__version__)\n",
        "print('keras integrada: versão', keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow:      versão 2.4.1\n",
            "keras integrada: versão 2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGgTb6zJFzEF"
      },
      "source": [
        "Este _notebook_ também utiliza a biblioteca `pydot` e a ferramenta Graphviz para visualizar as redes neurais. \n",
        "\n",
        "Ambos já fazem parte do ambiente Colaboratory.\n",
        "\n",
        "**Atenção:** para quem utiliza o ambiente Jupyter, é preciso primeiro instalar os pacotes `pydot` e `graphviz`. Na linha de comando isso pode ser feito assim:\n",
        "\n",
        "    conda install pydot graphviz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyKnzRJXFzEG"
      },
      "source": [
        "import pydot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qga_MCxCFzEG"
      },
      "source": [
        "# Perceptrons\n",
        "\n",
        "A biblioteca Scikit-Learn fornece um algoritmo `Perceptron` que implementa uma arquitetura com um único neurônio TLU.\n",
        "\n",
        "Esta rede neural pode ser usada diretamente como um classificador binário. Aqui o exemplo é feito com o _dataset_ IRIS.\n",
        "\n",
        "Ao contrário dos classificadores de regressão logística, os Perceptrons não geram uma probabilidade de classe. Em vez disso, eles apenas fazem previsões com base em um limite rígido. Esta é uma das boas razões para preferir o algoritmo `LogisticRegression` ao invés do `Perceptron`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlGucrrRFzEI"
      },
      "source": [
        "# leitura do dataset\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, (2, 3)]  # comprimento da pétala, largura da pétala\n",
        "y = (iris.target == 0).astype(np.int)\n",
        "\n",
        "# criação e treinamento do modelo\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "per_clf = Perceptron(random_state=42)\n",
        "per_clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NeuUYPVFzEJ"
      },
      "source": [
        "# previsão\n",
        "\n",
        "y_pred = per_clf.predict([[2, 0.5]])\n",
        "y_pred[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dTCsiNrFzEK"
      },
      "source": [
        "O código abaixo obtém o coeficiente e o ponto de interseção da fronteira de decisão (no caso, uma reta) e a exibe, junto com algumas instâncias do conjunto de treino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skz-bQ9jFzEM"
      },
      "source": [
        "# não se preocupe com os detalhes deste código\n",
        "\n",
        "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
        "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
        "\n",
        "axes = [0, 5, 0, 2]\n",
        "x0, x1 = np.meshgrid(np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
        "                     np.linspace(axes[2], axes[3], 200).reshape(-1, 1))\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "y_predict = per_clf.predict(X_new)\n",
        "zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], 'bs', label='outra')\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], 'yo', label='Iris setosa')\n",
        "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], 'k-', linewidth=3)\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
        "plt.xlabel('comprimento da pétala', fontsize=14)\n",
        "plt.ylabel('largura da pétala', fontsize=14)\n",
        "plt.legend(loc='lower right', fontsize=14)\n",
        "plt.axis(axes)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkyCmdMqFzEN"
      },
      "source": [
        "# Construindo um classificador de imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E6IrPzBFzEN"
      },
      "source": [
        "O primeiro passo é carregar um conjunto de daos. No caso, usamos aqui o _dataset_ **Fashion MNIST**, com imagens reduzidas de roupas. A biblioteca Keras tem várias funções para carregar conjuntos de dados populares em `keras.datasets`. \n",
        "\n",
        "O conjunto de dados já está dividido entre instâncias de treinamento e de teste, mas a seguir iremos dividir o conjunto de treinamento para ter um conjunto de validação.\n",
        "\n",
        "Cada instância é uma imagem em tons de cinza (com valores de 0 a 255) e com resolução 28 por 28 _pixels_. Note que esse _dataset_ foi feito para ser compatível com o conjunto **MNIST** original, tendo a mesma resolução, número de instâncias e número de classes (10), porém sendo mais desafiador de classificar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLndlrWDFzEN"
      },
      "source": [
        "# importação do dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "print('treinamento completo:', X_train_full.shape)\n",
        "print('testes:              ', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlgS9wV7FzEO"
      },
      "source": [
        "Aqui o conjunto completo de treinamento é quebrado em dois, um de treinamento menor e outro de validação. Também é feita a conversão dos valores inteiros de tons de cinza (de 0 a 255) para um vaor real no intervalo de 0 a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGMH56oyFzEO"
      },
      "source": [
        "# separação dos dados de treinamento e validação\n",
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255.\n",
        "print('treinamento:', X_train.shape)\n",
        "print('validação:   ', X_valid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q30n0bRcFzEP"
      },
      "source": [
        "Abaixo é exibida primeira instância do conjunto de treino:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2DORva5FzEP"
      },
      "source": [
        "plt.imshow(X_train[0], cmap='binary')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goHku5LZFzEQ"
      },
      "source": [
        "Os rótulos são valores inteiros de 0 a 9, quardados nos vetores `y` e que correspondem aos seguintes nomes de classes.\n",
        "\n",
        "Então a instância 0 é um **casaco**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtQdsMMFzEQ"
      },
      "source": [
        "class_names = ['camiseta', 'calça', 'pulôver', 'vestido', 'casaco',\n",
        "               'sandália', 'camisa', 'tênis', 'bolsa', 'bota']\n",
        "class_names[y_train[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R2IFwKhFzER"
      },
      "source": [
        "Abaixo é exibido um mosaico com várias instâncias do conjunto de treino:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S67rSQ9vFzER"
      },
      "source": [
        "# não se preocupe com este código\n",
        "\n",
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap='binary')\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6K9zoE5FzER"
      },
      "source": [
        "# Criando uma rede neural\n",
        "\n",
        "Aqui vamos criar uma rede neural de classificação, usando um modelo (ou arquitetura) do tipo sequencial. O modelo sequencial corresponde ao tipo mais simples de rede neural, onde uma sequência de camadas de neurônios é empilhada uma em cima da outra.\n",
        "\n",
        "- A criação começa com a chamada a `Sequential`, que define o tipo do modelo:\n",
        "\n",
        "        model = keras.models.Sequential()\n",
        "\n",
        "- Então uma camada do tipo `Flatten` é adicionada. Seu papel é apenas transformar a matriz de _pixels_ em um longo vetor. É uma camada de preprocessamento dos dados. Mas como esta é a primeira camada, é preciso definir o formato da entrada com `input_shape`:\n",
        "\n",
        "        model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "\n",
        "- A seguir adicionamos uma camada densa do tipo `Dense`, ou seja, totalmente conectada com a camada anterior. Esta conta com 300 neurônios e função de ativação ReLU:\n",
        "\n",
        "        model.add(keras.layers.Dense(300, activation='relu'))\n",
        "        \n",
        "- Então uma segunda camada `Dense` é adicionada, agora com 100 neurônios e função de ativação também ReLU:\n",
        "        \n",
        "        model.add(keras.layers.Dense(100, activation='relu'))\n",
        "        \n",
        "- Finalmente uma camada de saída é adicionada. Aqui o tipo também é `Dense`, mas a função de ativação é trocada para `softmax` para produzir a saída de classificador (uma vez que as classes são mutuamente exclusivas):\n",
        "        \n",
        "        model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "Ainda que se possa criar uma rede neural com as diversas chamadas a `model.add(...)`, é mais conveniente criar o modelo passando uma lista de camadas, como mostrado a seguir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqaIO9f8FzES"
      },
      "source": [
        "# comando para 'zerar' a biblioteca Keras\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# definição de sementes aleatórias\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOH7jRFvFzET"
      },
      "source": [
        "# especificação do modelo\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation='relu'),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENAuv2WqFzET"
      },
      "source": [
        "# resumo legível da arquitetura deste modelo\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A74KcxDiFzEU"
      },
      "source": [
        "Note que as camadas densas geralmente têm muitos parâmetros. Por exemplo, a primeira camada densa tem pesos de conexão de 784 × 300, além de mais 300 termos de _bias_, chegando a um total de 235.500 parâmetros.\n",
        "\n",
        "Isso dá ao modelo bastante flexibilidade para ajustar os dados de treinamento, mas também significa que o modelo corre o risco de ter _overfitting_, especialmente quando não há muitos dados de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F29enauHFzEU"
      },
      "source": [
        "## Arquitetura da rede neural\n",
        "\n",
        "Podemos gerar uma figura da arquitetura deste modelo usando a função `keras.utils.plot_model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHEgELLyFzEU"
      },
      "source": [
        "keras.utils.plot_model(model, 'fashion_mnist_model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgZ2qIcqFzEV"
      },
      "source": [
        "## Acesso às camadas\n",
        "\n",
        "A biblioteca permite acessar cada camada criada, usando índices de acesso tal como em uma lista de Python.\n",
        "\n",
        "Permite também ver atributos de cada camada, como o nome ou se é uma camada oculta. E ainda permite inspecionar os pesos de todas as conexões daquela camada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSWwPE5VFzEV"
      },
      "source": [
        "# acesso a cada uma das camadas\n",
        "model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V8rBsVoFzEW"
      },
      "source": [
        "# primeira camada e respectivo nome\n",
        "hidden1 = model.layers[1]\n",
        "hidden1.name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvf9hgcFFzEW"
      },
      "source": [
        "# encontra camada pelo nome\n",
        "model.get_layer(hidden1.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFZUVqN2FzEY"
      },
      "source": [
        "# indica se a camada é ou não oculta\n",
        "model.get_layer(hidden1.name) is hidden1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9l7CapdFzEY"
      },
      "source": [
        "Observe que a camada `Dense` inicializa os pesos das conexão aleatoriamente. Os vieses foram inicializados apenas com zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRjMc_BaFzEY"
      },
      "source": [
        "# obtém pesos e vieses da camada\n",
        "weights, biases = hidden1.get_weights()\n",
        "print('weights:', weights.shape)\n",
        "print('biases: ', biases.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkvaAq_uFzEZ"
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxX2GKzJFzEZ"
      },
      "source": [
        "biases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmJF24bjFzEa"
      },
      "source": [
        "## Compilando a rede neural\n",
        "\n",
        "Depois que um modelo é criado, é preciso chamar o método `compile()`, especificando a **função de perda** (aqui, a função `sparse_categorical_crossentropy`) e o **otimizador** a ser usado (`sgd`, algoritmo de descida do gradiente estocástico).\n",
        "\n",
        "Opcionalmente, você também pode especificar uma lista de **medidas de desempenho** extras para calcular durante o treinamento e avaliação. Neste caso apenas é indicada a acurácia com `accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8qZT7UdFzEa"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVeVoB2qFzEa"
      },
      "source": [
        "# Treinando e avaliando a rede neural\n",
        "\n",
        "Para treinar o modelo basta chamar o método `fit()`. \n",
        "\n",
        "Três parâmetros são obrigatórios: as _features_ de treinamento, os rótulos de treinamento e o número de épocas.\n",
        "\n",
        "Cada **época** (_epoch_) corresponde a uma etapa de atualização da rede neural.\n",
        "\n",
        "Opcionalemente é passado também um conjunto de validação. A biblioteca Keras medirá a perda e as métricas extras ao final de cada época, o que é muito útil para ver como o modelo realmente funciona: se o desempenho no conjunto de treinamento é muito melhor do que no conjunto de validação, provavelmente está ocorrendo _overfitting_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcTzUE33FzEb"
      },
      "source": [
        "# esta chamada pode demorar um pouco\n",
        "%time history = model.fit(X_train, y_train, epochs=25, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jK6oX2yFzEb"
      },
      "source": [
        "# os dados do treinamento estão disponíveis no histórico retornado\n",
        "print('parâmetros:', history.params)\n",
        "print('métricas:  ', list(history.history.keys()))\n",
        "print('épocas:    ', history.epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VTFBTMdFzEb"
      },
      "source": [
        "## Visualização da evolução das métricas ao longo do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXm1A2g8FzEb"
      },
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(12, 6))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGY2eqMnFzEc"
      },
      "source": [
        "## Avaliação final do modelo e geração de previsões"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8uKMDzAFzEc"
      },
      "source": [
        "# avaliação com conjunto de teste\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNbEZkq3FzEd"
      },
      "source": [
        "# probabilidades computadas para três instâncias de teste\n",
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "print(y_proba.round(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYxYZ4FcFzEd"
      },
      "source": [
        "# classes previstas e reais para as mesmas três instâncias de teste\n",
        "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
        "print('previstas: ', np.array(class_names)[y_pred])\n",
        "print('reais:     ', np.array(class_names)[y_test[:3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz1zIy0dFzEe"
      },
      "source": [
        "# visualização das tres instâncias\n",
        "plt.figure(figsize=(7.2, 2.4))\n",
        "for index, image in enumerate(X_new):\n",
        "    plt.subplot(1, 3, index + 1)\n",
        "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
        "    plt.axis('off')\n",
        "    plt.title(class_names[y_test[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}