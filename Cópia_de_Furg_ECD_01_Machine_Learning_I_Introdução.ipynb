{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "toc_position": {
      "height": "616px",
      "left": "0px",
      "right": "20px",
      "top": "106px",
      "width": "213px"
    },
    "colab": {
      "name": "Cópia de Furg - ECD 01 - Machine Learning I - Introdução",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcpiscator/01T2021/blob/main/C%C3%B3pia_de_Furg_ECD_01_Machine_Learning_I_Introdu%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-w19xbZHcOB"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning I - Introdução\n",
        "### Prof. Marcelo de Gomensoro Malheiros\n",
        "\n",
        "Código adaptado de Aurélien Geron (licença Apache-2.0)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j563P0ljHcOM"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_:\n",
        "\n",
        "- NumPy: suporte a vetores, matrizes e operações de Álgebra Linear\n",
        "- Matplotlib: biblioteca de visualização de dados\n",
        "- Pandas: pacote estatístico e de manipulação de DataFrames\n",
        "- scikit-learn: biblioteca com algoritmos de Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwKa7uu0HcON"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfbvJmxkBiAQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-HV97uSHcOO"
      },
      "source": [
        "# Etapa 1: Análise dos dados e seleção de _features_\n",
        "\n",
        "## Importação dos dados\n",
        "\n",
        "As bases de dados utilizadas são duas.\n",
        "\n",
        "A primeira é também um arquivo CSV, contendo informações sobre o Produto Interno Bruto per Capita (GDP, em inglês) de diversos países. Os dados vieram do Fundo Monetário Internacional (FMI), em https://www.imf.org/en/Publications/SPROLLs/world-economic-outlook-databases\n",
        "\n",
        "A segunda é um arquivo CSV, contendo índices de satisfação por país tabulados pela Organização para a Cooperação e Desenvolvimento Econômico (OECD, em inglês). Os dados originais estão em http://stats.oecd.org/index.aspx?DataSetCode=BLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctz9cKHNHcOQ"
      },
      "source": [
        "# importação usando Pandas\n",
        "\n",
        "gdp_per_capita = pd.read_csv('gdp_per_capita.csv', thousands=',', delimiter='\\t', \n",
        "                             encoding='latin1', na_values='n/a')\n",
        "gdp_per_capita.rename(columns={'2015': 'GDP per capita'}, inplace=True)\n",
        "gdp_per_capita.set_index('Country', inplace=True)\n",
        "\n",
        "oecd_bli = pd.read_csv('oecd_bli_2015.csv',  thousands=',')\n",
        "oecd_bli = oecd_bli[oecd_bli['INEQUALITY']=='TOT']\n",
        "oecd_bli = oecd_bli.pivot(index='Country', columns='Indicator', values='Value')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72VNKxGhHcOR"
      },
      "source": [
        "gdp_per_capita.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS0EbQPbHcOU"
      },
      "source": [
        "oecd_bli.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMKhe3PzHcOV"
      },
      "source": [
        "# novo DataFrame combinando as duas bases\n",
        "\n",
        "full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita, left_index=True, right_index=True)\n",
        "full_country_stats.sort_values(by='GDP per capita', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5X1fKTVHcOV"
      },
      "source": [
        "full_country_stats.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAHS8S86HcOX"
      },
      "source": [
        "## Preparação dos dados\n",
        "\n",
        "Para simplificar a análise, os campos importantes das duas bases são colocados em um novo DataFrame chamado `country_stats`, com um conjunto menor de países.\n",
        "\n",
        "O índice da nova base é o nome do país (em inglês), e os atributos selecionados são o produto interno bruto per capita `GDP per capita` e índice de satisfação pessoal `Life satisfaction`.\n",
        "\n",
        "A idéia é verificar se o o produto interno bruto per capita é uma _feature_ adequada para prever o índice de satisfação pessoal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTIqNgHhHcOY"
      },
      "source": [
        "remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
        "keep_indices = list(set(range(36)) - set(remove_indices))\n",
        "country_stats = full_country_stats[['GDP per capita', 'Life satisfaction']].iloc[keep_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30vB6reoHcOZ"
      },
      "source": [
        "country_stats.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnz3SYrdHcOa"
      },
      "source": [
        "# Etapa 2: Escolha da abordagem de ML\n",
        "\n",
        "Como os dois atributos são valores reais, é natural tentar uma abordagem de regressão numérica. Em particular, o tipo mais simples de regressão: uma **regressão linear**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90AfXfvIHcOa"
      },
      "source": [
        "# extração das colunas 'GDP per capita' para 'X' e 'Life satisfaction' para y\n",
        "\n",
        "X = np.c_[country_stats['GDP per capita']]\n",
        "y = np.c_[country_stats['Life satisfaction']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7O3nPGuHcOa"
      },
      "source": [
        "# visualização dos dados\n",
        "\n",
        "country_stats.plot(kind='scatter', x='GDP per capita', y='Life satisfaction')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pNJhvJMHcOb"
      },
      "source": [
        "# Etapa 3: Definição do modelo e de seus parâmetros\n",
        "\n",
        "Como uma regressão linear é bastante simples, os parâmetros a serem aprendidos são simplesmente os coeficientes da melhor reta de ajuste.\n",
        "\n",
        "Documentação: https://scikit-learn.org/stable/modules/linear_model.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS9ftcCYHcOc"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# criação do modelo\n",
        "model = linear_model.LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3JZHHlpHcOc"
      },
      "source": [
        "# Etapa 4: Treino com os dados de treinamento\n",
        "\n",
        "Basta fornecer os dados preditores da série `X` e os respectivos valores conhecidos em `y` para o método `fit()` do modelo.\n",
        "\n",
        "Os parâmetros para o melhor ajuste a esse conjunto de treinamento são obtidos nos atributos `intercept_` e `coef_`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQqUrrhGHcOc"
      },
      "source": [
        "# treinando o modelo\n",
        "model.fit(X, y)\n",
        "\n",
        "# parâmetros do modelo (inclinação e ponto de interseção da reta) aprendidos\n",
        "theta_0 = model.intercept_[0]\n",
        "theta_1 = model.coef_[0, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB44mLXUHcOd"
      },
      "source": [
        "Em geral o parâmetros de um modelo são representados pela letra grega $\\theta$ (teta).\n",
        "\n",
        "No caso de uma regressão linear, correspondem ao ponto de interseção com o eixo horizontal e com a inclinação da reta de aproximação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dZnKRASHcOd"
      },
      "source": [
        "country_stats.plot(kind='scatter', x='GDP per capita', y='Life satisfaction', figsize=(10,4))\n",
        "\n",
        "# plotagem da reta\n",
        "X = np.linspace(0, 60000, 10)\n",
        "plt.plot(X, theta_0 + theta_1 * X, 'b')\n",
        "\n",
        "# legenda\n",
        "plt.text(5000, 7.5, '$\\\\theta_1$ = {:.6f}'.format(theta_1), fontsize=14, color=\"b\")\n",
        "plt.text(5000, 7.0, '$\\\\theta_0$ = {:.2f}'.format(theta_0), fontsize=14, color=\"b\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtCVlSpUHcOe"
      },
      "source": [
        "# Etapa 5: Avaliação com os dados de teste\n",
        "\n",
        "Pode-se avaliar a qualidade do modelo ao se comparar valores previstos com valores reais, para outros dados. Isso será feito com **medidas de desempenho** (_performance measures_), a serem analisadas em breve.\n",
        "\n",
        "É importante que estes dados de teste **não façam parte dos dados de treinamento**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd6xdijTHcOe"
      },
      "source": [
        "# valores reais do produto interno bruto per capita e satisação pessoal\n",
        "brazil_gdp = full_country_stats['GDP per capita']['Brazil']\n",
        "brazil_sat = full_country_stats['Life satisfaction']['Brazil']\n",
        "\n",
        "# previsão\n",
        "X = [[brazil_gdp]]\n",
        "y = model.predict(X)\n",
        "predic_sat = y[0, 0]\n",
        "\n",
        "print('Brasil, satisfação prevista: {:.2f}'.format(predic_sat))\n",
        "print('Brasil, satisfação real:     {:.2f}'.format(brazil_sat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQth5Jb3HcOf"
      },
      "source": [
        "# Etapa 6: Aplicação do modelo para fazer previsões sobre novos casos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN1gt2ROHcOf"
      },
      "source": [
        "# não há informações sobre satisação pessoal do Chipre nos dados da OECD\n",
        "cyprus_gdp = gdp_per_capita['GDP per capita']['Cyprus']\n",
        "\n",
        "# previsão\n",
        "X = [[cyprus_gdp]]\n",
        "y = model.predict(X)\n",
        "predic_sat = y[0, 0]\n",
        "\n",
        "print('Chipre, satisfação prevista: {:.2f}'.format(predic_sat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnWld0WiHcOg"
      },
      "source": [
        "country_stats.plot(kind='scatter', x='GDP per capita', y='Life satisfaction', figsize=(10,4))\n",
        "\n",
        "# plotagem da reta\n",
        "X = np.linspace(0, 60000, 10)\n",
        "plt.plot(X, theta_0 + theta_1 * X, 'b')\n",
        "\n",
        "# mostra previsão para Chipre\n",
        "plt.plot([cyprus_gdp, cyprus_gdp], [4.8, predic_sat], 'r--')\n",
        "plt.plot(cyprus_gdp, predic_sat, 'ro')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAP_El4HcOh"
      },
      "source": [
        "---\n",
        "\n",
        "# Principais desafios de Machine Learning\n",
        "\n",
        "## a. Quantidade insuficiente de dados de treinamento\n",
        "\n",
        "São necessários muitos dados para que a maioria dos algoritmos de aprendizado de máquina funcione corretamente.\n",
        "\n",
        "Mesmo para problemas muito simples, normalmente são necessários milhares de exemplos. Para problemas complexos, como imagem ou reconhecimento de voz, são precisos de milhões de exemplos (a menos que se possa reutilizar partes de um modelo existente)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kODcqOJHcOh"
      },
      "source": [
        "## b. Dados de treinamento não representativos\n",
        "\n",
        "Para generalizar adequadamente, é crucial que os dados de treinamento sejam representativos dos novos casos para os quais se deseja generalizar.\n",
        "\n",
        "Por exemplo, o conjunto de países usado anteriormente para treinar a regressão linear não era perfeitamente representativo: alguns países estavam faltando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvY4DbVPHcOh"
      },
      "source": [
        "missing_data = full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[remove_indices]\n",
        "missing_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqOyID45HcOh"
      },
      "source": [
        "O gráfico abaixo mostra a aparência dos dados quando se adiciona os países ausentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKXGmPIfHcOh"
      },
      "source": [
        "country_stats.plot(kind='scatter', x='GDP per capita', y='Life satisfaction', figsize=(12,4))\n",
        "\n",
        "# plotagem da reta\n",
        "X = np.linspace(0, 105000, 1000)\n",
        "plt.plot(X, theta_0 + theta_1 * X, 'b')\n",
        "\n",
        "# plotagem dos novos dados\n",
        "text_pos = {'Brazil': (1000, 9), 'Mexico': (11000, 9), 'Chile': (25000, 9), 'Czech Republic': (35000, 9),\n",
        "            'Norway': (60000, 5), 'Switzerland': (72000, 5), 'Luxembourg': (90000, 5)}\n",
        "for country, pos in text_pos.items():\n",
        "    data_x, data_y = missing_data.loc[country]\n",
        "    plt.plot(data_x, data_y, 'ro')\n",
        "    plt.annotate(country, xy=(data_x, data_y), xytext=pos, \n",
        "                 arrowprops=dict(facecolor='black', width=0.5, headwidth=5))\n",
        "\n",
        "# novo modelo\n",
        "full_model = linear_model.LinearRegression()\n",
        "full_X = np.c_[full_country_stats['GDP per capita']]\n",
        "full_y = np.c_[full_country_stats['Life satisfaction']]\n",
        "full_model.fit(full_X, full_y)\n",
        "\n",
        "# plotagem da nova reta\n",
        "full_theta_0 = full_model.intercept_[0]\n",
        "full_theta_1 = full_model.coef_[0, 0]\n",
        "X = np.linspace(0, 105000, 1000)\n",
        "plt.plot(X, full_theta_0 + full_theta_1 * X, 'r')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olJVKkHZHcOi"
      },
      "source": [
        "Usando um conjunto de treinamento não representativo, treinamos um modelo que dificilmente fará previsões precisas, especialmente para países muito pobres e muito ricos.\n",
        "\n",
        "Então é crucial usar um conjunto de treinamento que seja representativo dos casos para os quais você deseja generalizar. \n",
        "\n",
        "Isso geralmente é mais difícil do que parece: se a amostra for muito pequena, você terá **ruído de amostragem** (_sampling noise_), quando dados não representativos são resultado do acaso.\n",
        "\n",
        "Mesmo amostras muito grandes podem ser não representativas se o método de amostragem for falho. Isso é chamado de **viés de amostragem** (_sampling bias_)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4rY1umKHcOj"
      },
      "source": [
        "## c. Dados de baixa qualidade\n",
        "\n",
        "Se os dados de treinamento estiverem cheios de erros, ruídos (devido a medições de baixa qualidade) e valores discrepantes, será mais difícil para o sistema detectar os padrões subjacentes.\n",
        "\n",
        "Então, é menos provável que o sistema tenha um bom desempenho. Geralmente, vale a pena gastar tempo limpando os dados de treinamento. De fato, a maioria dos cientistas de dados gasta uma parte significativa de seu tempo fazendo isso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhMX4LcLHcOj"
      },
      "source": [
        "## d. Features irrelevantes\n",
        "\n",
        "    \"garbage in, garbage out\"\n",
        "\n",
        "Um sistema só será capaz de aprender se os dados de treinamento contiverem _features_ relevantes suficientes e não muitas _features_ irrelevantes. Uma parte crítica do sucesso de um projeto de Machine Learning é identificar um bom conjunto de _features_ para treinar.\n",
        "\n",
        "Este processo, denominado de Engenharia de _Features_, envolve:\n",
        "\n",
        "- Seleção de _features_, escolhendo os atributos mais úteis para treinar entre os atributos existentes.\n",
        "\n",
        "- Extração de _features_, combinando _features_ existentes para produzir uma _feature_ mais útil.\n",
        "\n",
        "- Criação de novas _features_ por meio da coleta de novos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg4QubxDHcOj"
      },
      "source": [
        "## e. Overfitting\n",
        "\n",
        "Um modelo sofre de _overfitting_ quando ele tem um bom desempenho nos dados de treinamento, mas não generaliza bem para novos dados.\n",
        "\n",
        "Por exemplo, um modelo polinomial de grau elevado se ajusta muito bem aos dados de treinamento. Embora tenha um desempenho muito melhor nestes dados do que o modelo linear simples, este não é capaz de generalizar adequadamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqTdQ27MHcOj"
      },
      "source": [
        "full_country_stats.plot(kind='scatter', x='GDP per capita', y='Life satisfaction', figsize=(12,4))\n",
        "\n",
        "# funcionalidades auxiliares\n",
        "from sklearn import preprocessing\n",
        "from sklearn import pipeline\n",
        "poly = preprocessing.PolynomialFeatures(degree=60, include_bias=False)\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "# novo modelo\n",
        "new_model = linear_model.LinearRegression()\n",
        "pipeline_reg = pipeline.Pipeline([('poly', poly), ('scal', scaler), ('lin', new_model)])\n",
        "pipeline_reg.fit(full_X, full_y)\n",
        "\n",
        "# plotagem da nova curva\n",
        "X = np.linspace(0, 105000, 1000)\n",
        "curve = pipeline_reg.predict(X[:, np.newaxis])\n",
        "plt.axis([0, 105000, 4.5, 10.3])\n",
        "plt.plot(X, curve)\n",
        "plt.show()\n",
        "\n",
        "# NOTA: é esperada a impressão de advertências abaixo, que refletem problemas numéricos desse modelo polinomial"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErVkrnEdHcOk"
      },
      "source": [
        "Modelos complexos podem detectar padrões sutis nos dados, mas se o conjunto de treinamento for ruidoso ou muito pequeno (o que introduz ruído de amostragem), o modelo provavelmente detectará padrões no próprio ruído.\n",
        "\n",
        "Tais padrões não são úteis para a etapa de generalização.\n",
        "\n",
        "Em resumo, o _overfitting_ ocorre quando o modelo é muito complexo em relação à quantidade e ao ruído dos dados de treinamento. As soluções possíveis são:\n",
        "\n",
        "- Simplificar o modelo: selecionar um modelo com menos parâmetros, reduzir o número de _features_ nos dados de treinamento ou restringir o modelo (com um processo de **regularização**, a ser visto posteriormente).\n",
        "\n",
        "- Coletar mais dados de treinamento.\n",
        "\n",
        "- Reduzir o ruído nos dados de treinamento (tipicamente corrigindo erros nos dados e removendo _outliers_)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E08JC3SdHcOk"
      },
      "source": [
        "## f. Underfitting\n",
        "\n",
        "O fenômeno de _underfitting_ é o oposto de _overfitting_: ele ocorre quando o modelo é muito simples para aprender a estrutura subjacente dos dados.\n",
        "\n",
        "Por exemplo, um modelo linear de satisfação pessoal tende a ser insuficiente; a realidade é bem mais complexa do que o modelo, então suas previsões estão fadadas a serem imprecisas, mesmo nos exemplos de treinamento.\n",
        "\n",
        "As principais opções para corrigir o problema de _underfitting_ são:\n",
        "\n",
        "- Selecionar um modelo mais poderoso, com mais parâmetros.\n",
        "\n",
        "- Alimentar o algoritmo de aprendizado com melhores _features_.\n",
        "\n",
        "- Reduzir as restrições do modelo (ajustando o processo de regularização)."
      ]
    }
  ]
}