{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Cópia de Furg - ECD 09 - Machine Learning I - Tarefa: Dados do ENEM",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcpiscator/01T2021/blob/main/C%C3%B3pia_(exerc%C3%ADcio)_de_Furg_ECD_09_Machine_Learning_I_Tarefa_Dados_do_ENEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0znIla-40Blp"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning I - Tarefa: Dados do ENEM\n",
        "### Prof. Marcelo Malheiros\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj3JrbGZ0Bl1"
      },
      "source": [
        "Esta tarefa é para você **observar** e **analisar** este processo de Machine Learning.\n",
        "\n",
        "Adicionalmente, sugere-se que você também experimente com os dados e com os algoritmos, fazendo algumas das modificações indicadas em várias partes deste _notebook_.\n",
        "\n",
        "Note que não é preciso escrever mais código, apenas modificar o código já fornecido.\n",
        "\n",
        "Um questionário _online_ dentro da disciplina no AVA será disponibilizado para coletar sua análise. Este questionário será também uma das tarefas avaliativas desta disciplina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IzHUC6D0Bl3"
      },
      "source": [
        "# Problema\n",
        "\n",
        "O problema aqui descrito é uma **tarefa de regressão**. Com base nos dados reais das escolas do Ensino Médio avaliadas pelo ENEM em 2014 e 2015, precisamos ajustar um **modelo de previsão** para ser capaz de prever as médias das provas de Matemática e de Redação, separadamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhUfEFMX0Bl4"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oxaThQi0Bl6"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESy-zu4u0Bl8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print('tensorflow:      versão', tf.__version__)\n",
        "print('keras integrada: versão', keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P5p0SfJ0Bl_"
      },
      "source": [
        "# Conjunto de dados\n",
        "\n",
        "Este _dataset_ deve ser baixado pelo analista diretamente do site do Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira (INEP):\n",
        "\n",
        "[Microdados do Exame Nacional do Ensino Médio por Escola](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem-por-escola)\n",
        "\n",
        "Os dados estão presentes em um único arquivo no formato CSV na pasta `DADOS`, chamado `MICRODADOS_ENEM_ESCOLA.csv`.\n",
        "\n",
        "A explicação sobre o layout dos dados e valores categóricos está dentro na pasta `DICIONÁRIO`, no arquivo `Dicionário_Microdados_Enem_Escola.xlsx`.\n",
        "\n",
        "As descrições detalhadas do conjunto de dados estão na pasta `LEIA-ME e DOCUMENTOS TÉCNICOS`.\n",
        "\n",
        "A leitura dos dados é feita a seguir, definido `;` como separador entre os campos. A opção `low_memory=False` é usada para fazer um exame mais detalhado do arquivo antes da leitura.\n",
        "\n",
        "Note que para arquivos com palavras em Português é preciso tomar cuidado com a codifição dos campos de texto. Por padrão a codificação é `encoding='utf_8'`. Porém, se os acentos aparecem errados provavelmente a codificação precisa ser `encoding='latin_1'`, como foi o caso aqui.\n",
        "\n",
        "**Não se esqueça de fazer o upload do arquivo `MICRODADOS_ENEM_ESCOLA.csv` para o Colaboratory, antes de rodar a célula a seguir.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjAvmuDi0BmA"
      },
      "source": [
        "# leitura dos conjuntos de dados\n",
        "\n",
        "enem_original = pd.read_csv('MICRODADOS_ENEM_ESCOLA.csv', sep=';', encoding='latin_1', low_memory=False) # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWCYbM-K0BmC"
      },
      "source": [
        "O conjunto inteiro dos dados foi colocado em um `DataFrame` (da biblioteca Pandas).\n",
        "\n",
        "Vamos visualizar a seguir os primeiro cinco registros desta base:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKQ41jMC0BmC"
      },
      "source": [
        "enem_original.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbVjvB9j0BmE"
      },
      "source": [
        "Não vamos detalhar cada campo, pois os detalhes estão disponível no arquivo de dicionário.\n",
        "\n",
        "O importante aqui é notar que os dados abrangem diversos anos, estando **empilhados** nesta base. Então uma mesma escola, representada pelo código `CO_ESCOLA_EDUCACENSO` aparece em diversas linhas, uma para cada ano em que participou.\n",
        "\n",
        "Então, por enquanto, usaremos o índice numérico automaticamente criado pela biblioteca Pandas (valores em negrito, à esquerda)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83VF5EJC0BmG"
      },
      "source": [
        "# Análise dos dados\n",
        "\n",
        "Aqui vamos computar algumas estatísticas sobre a base original de dados. Estas estatísticas são importantes tanto para perceber quais operações de preprocessamento serão necessárias como para escolher quais _features_ vamos usar no treinamento.\n",
        "\n",
        "Uma função muito útil para isso é a `.info()`, que mostra o tipo de dados e o número de valores presentes em cada coluna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSg1ZGZY0BmG"
      },
      "source": [
        "enem_original.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF9byJ8j0BmH"
      },
      "source": [
        "Para este conjunto há um total de 172305 registros. Mas o número de escolas é muito menor, uma vez que esta base abrange dados de 2005 até 2015.\n",
        "\n",
        "Além desta séries históricas estarem empilhadas, outro desafio desta base é que alguns atributos so valem para determinados anos, como `NU_MEDIA_OBJ` e `NU_MEDIA_TOT`. Isso implica em uma grande quantidade de valores faltantes, representados como `NaN` na visualização acima.\n",
        "\n",
        "Vamos então iniciar removendo colunas que não são de interesse. Iremos descartar os atributos (colunas) sobre as unidade federativa e municípios das escolas, assim como todas as médias de provas que não sejam Matemática ou Redação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4-9f3550BmI"
      },
      "source": [
        "enem_original.drop(columns=['CO_UF_ESCOLA', 'SG_UF_ESCOLA', 'CO_MUNICIPIO_ESCOLA', 'NO_MUNICIPIO_ESCOLA', \n",
        "                   'NU_MEDIA_CN', 'NU_MEDIA_CH', 'NU_MEDIA_LP', 'NU_MEDIA_OBJ', 'NU_MEDIA_TOT'], inplace=True)\n",
        "enem_original.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8npzDUB0BmJ"
      },
      "source": [
        "Note que fomos de 27 atributos para 18 agora.\n",
        "\n",
        "Podemos também olhar estatísticas sobre os valores das colunas numéricas usando `.describe()':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJYDqy8s0BmJ"
      },
      "source": [
        "enem_original.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzSGuD_50BmL"
      },
      "source": [
        "Vale a pena também analisar as colunas que contém poucos valores, chamadas de categóricas, para identificar as classes presentes. Faremos isso chamando a função `.value_counts()` em cada uma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBKtubQ_0BmL"
      },
      "source": [
        "enem_original['NU_ANO'].value_counts().sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJYL30qN0BmL"
      },
      "source": [
        "# esta coluna foi lida como numérica, mas por ser um valor categórico vamos converter para string\n",
        "enem_original['TP_DEPENDENCIA_ADM_ESCOLA'] = enem_original['TP_DEPENDENCIA_ADM_ESCOLA'].astype('str')\n",
        "enem_original['TP_DEPENDENCIA_ADM_ESCOLA'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6JTipsV0BmL"
      },
      "source": [
        "# esta coluna foi lida como numérica, mas por ser um valor categórico vamos converter para string\n",
        "enem_original['TP_LOCALIZACAO_ESCOLA'] = enem_original['TP_LOCALIZACAO_ESCOLA'].astype('str')\n",
        "enem_original['TP_LOCALIZACAO_ESCOLA'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hkITkPw0BmM"
      },
      "source": [
        "enem_original['INSE'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcf32scT0BmN"
      },
      "source": [
        "enem_original['PORTE_ESCOLA'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaQ0LBAJ0BmN"
      },
      "source": [
        "Queremos prever os atributos NU_MEDIA_MT (média da prova de Matemática) e NU_MEDIA_RED (média da prova de redação) para o último disponível, 2015. A própria escala das provas mudou, e de 2009 a 2015 vai de 0 a 1000. \n",
        "\n",
        "Como os atributos que desejamos prever são numéricos, temos uma tarefa de **regressão**. Isso afeta diretamente quais algoritmos podemos usar para fazer o treino, posteriormente. E também a arquitetura de rede neural a ser utilizada.\n",
        "\n",
        "Então, como os valores a serem previstos são numericamente grandes, vamos utilizar como medida de desempenho o **erro absoluto médio** (_mean absolute error_, ou MAE). Isso é importante porque uma medida como RMSE é excessivamente sensível a variações maiores, e afetaria o próprio processo de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhBFykhn0BmO"
      },
      "source": [
        "# Reorganização dos dados\n",
        "\n",
        "Aqui vale a pena filtrar os dados, retendo apenas os registros para os anos de 2014 e 2015.\n",
        "\n",
        "Para isso vamos fazer primeiro uma operação de separação dos dados, com um `DataFrame` para 2014 e outro para 2015, apenas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIRO0nh50BmP"
      },
      "source": [
        "enem_2014 = enem_original[enem_original['NU_ANO'] == 2014]\n",
        "print(enem_2014.shape)\n",
        "\n",
        "enem_2015 = enem_original[enem_original['NU_ANO'] == 2015]\n",
        "print(enem_2015.shape)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_170gqm0BmP"
      },
      "source": [
        "Precisamos então fazer uma operação de fusão (_merge_) entre as duas tabelas.\n",
        "\n",
        "Isso é necessário para ter em uma única linha os atributos de uma mesma escola. Como teremos atributos de 2014 e 2015, podemos adicionar um prefixo para identificá-los na tabela resultante.\n",
        "\n",
        "Outra característica importante desta fusão é que a amarração se dará pelo código único da escola, `CO_ESCOLA_EDUCACENSO`. Isso fará que apenas escolas que tenham participado das provas de 2014 e de 2015 estejam presentes na tabela resultante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86pSn-V-0BmQ"
      },
      "source": [
        "enem = pd.merge(left=enem_2014, right=enem_2015, on='CO_ESCOLA_EDUCACENSO', suffixes=['_2014', '_2015'])\n",
        "enem.set_index('CO_ESCOLA_EDUCACENSO', inplace=True)\n",
        "enem.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpjm1SzB0BmQ"
      },
      "source": [
        "enem.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uhp5tPg0BmR"
      },
      "source": [
        "Aqui vamos retirar mais algumas colunas, deixando apenas as notas das provas de Matemática e Redação de 2014, e todos os dados restantes de 2015.\n",
        "\n",
        "**Ajuste:** Pode ser interessante analisar futuramente se a manutenção de algum desses dados históricos também ajuda na melhoria do modelo. Para isso basta repetir a operação de _merge_ acima e então retirar do comando _drop_ abaixo o nome das colunas a serem mantidas. Estas novas colunas deverão ser selecionadas explicitamente na etapa posterior de pré-processamento dos dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaK4ytxv0BmR"
      },
      "source": [
        "enem.drop(columns=['NU_ANO_2014', 'NU_ANO_2015', 'NO_ESCOLA_EDUCACENSO_2014',\n",
        "                   'TP_DEPENDENCIA_ADM_ESCOLA_2014', 'TP_LOCALIZACAO_ESCOLA_2014', 'NU_MATRICULAS_2014', \n",
        "                   'NU_PARTICIPANTES_NEC_ESP_2014', 'NU_PARTICIPANTES_2014', 'NU_TAXA_PARTICIPACAO_2014',\n",
        "                   'INSE_2014', 'PC_FORMACAO_DOCENTE_2014', 'NU_TAXA_PERMANENCIA_2014', 'NU_TAXA_APROVACAO_2014',\n",
        "                   'NU_TAXA_REPROVACAO_2014', 'NU_TAXA_ABANDONO_2014', 'PORTE_ESCOLA_2014'], inplace=True)\n",
        "enem.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiErAeTx0BmS"
      },
      "source": [
        "Esta então é a nossa base final de trabalho, chamada simplesmente `enem`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLKYvn9x0BmS"
      },
      "source": [
        "enem.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMZURFgH0BmS"
      },
      "source": [
        "enem.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmPONK-J0BmT"
      },
      "source": [
        "# Correlação entre atributos\n",
        "\n",
        "Apenas para gerar uma intuição sobre os dados, vamos visualizar a correlação entre todos atributos e um dos alvos, `NU_MEDIA_MT_2015`.\n",
        "\n",
        "Para isso usamos a função `.corr()` para calcular o coeficiente de correlação (também chamado de R de Pearson) entre cada par de atributos de um DataFrame. Note que aparecem apenas os **atributos numéricos**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2L6tNQU0BmT"
      },
      "source": [
        "# cálculo da matriz de correlação\n",
        "corr = enem.corr()\n",
        "\n",
        "# quanto cada atributo se correlaciona com o valor da prova de Matemática de 2015\n",
        "corr['NU_MEDIA_MT_2015'].sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZOvaaLy0BmU"
      },
      "source": [
        "Note que é possível visualizar a tabela inteira, que cruza cada os atributos com todos os demais, como visualizado abaixo. A escala de cores é de um azul mais intenso para valores negativos (no mínimo -1) e de vermelhos mais intensos para valores positivos (no máximo 1). Valores próximos ao zero são também mais próximos do branco.\n",
        "\n",
        "Ainda que haja correlação forte entre alguns atributos, para esta análise só interessam correlações envolvendo os atributos `NU_MEDIA_MT_2015` e `NU_MEDIA_RED_2015`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUoQFflF0BmU"
      },
      "source": [
        "corr.style.background_gradient(axis=None, cmap='bwr').set_precision(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5QjAeb_0BmV"
      },
      "source": [
        "# Separação dos dados\n",
        "\n",
        "Agora vamos separar cada conjunto de dados em duas partes: `features`, que são os atributos sobre os quais treinaremos o modelo, e `rotulos`, que contém os atributos a serem previstos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_6UKKfX0BmV"
      },
      "source": [
        "# rotulos\n",
        "rotulos = enem[['NU_MEDIA_MT_2015', 'NU_MEDIA_RED_2015']]\n",
        "\n",
        "# features\n",
        "features = enem.drop(columns=['NU_MEDIA_MT_2015', 'NU_MEDIA_RED_2015'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pw5JXFO0BmV"
      },
      "source": [
        "Vamos agora separar as _features_ e os rótulos em subconjuntos de treino e de testes.\n",
        "\n",
        "Não vamos precisar de conjuntos de validação, pois iremos utilizar depois a estratégia de validação cruzada para garantir que o modelo não está fazendo _overfitting_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IFsTWME0BmW"
      },
      "source": [
        "# separação em conjuntos de treino (80%) e de teste (20%)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "treino_features, teste_features, treino_rotulos, teste_rotulos = train_test_split(features, rotulos,\n",
        "                                                                                  random_state=42, \n",
        "                                                                                  train_size=0.80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-m44RaG0BmW"
      },
      "source": [
        "É importante verificar o número de linhas e de colunas para cada subconjunto criado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuC3D70H0BmW"
      },
      "source": [
        "print('treino_features:', treino_features.shape)\n",
        "print('treino_rotulos: ', treino_rotulos.shape)\n",
        "print('teste_features: ', teste_features.shape)\n",
        "print('teste_rotulos:  ', teste_rotulos.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYa6vV5_0BmX"
      },
      "source": [
        "print(treino_features.iloc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAYJQysC0BmX"
      },
      "source": [
        "print(treino_rotulos.iloc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcx9YnCv0BmX"
      },
      "source": [
        "# Preprocessamento\n",
        "\n",
        "Aqui faremos a etapa de preprocessamento, necessária para transformar os dados brutos em valores mais adequados para os algoritmos de Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY1xHdWr0BmY"
      },
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ6MiHJp0BmY"
      },
      "source": [
        "# aqui definimos uma etapa auxiliar do pipeline para atributos categóricos:\n",
        "# esta substitui valores faltando pelo mais frequente de cada coluna\n",
        "# (não se preocupe com os detalhes do código)\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index=X.columns)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.most_frequent_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phTgvXW80BmZ"
      },
      "source": [
        "Atributos numéricos (contínuos) e atributos categóricos (discretos) precisam ser processados separadamente.\n",
        "\n",
        "O trecho a seguir define um _pipeline_ genérico, apenas para os atributos numéricos. A etapa usando `SimpleImputer(strategy='median')` preenche valores faltando com a mediana dos valores daquele atributo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi3eY4DS0BmZ"
      },
      "source": [
        "# pipeline para atributos numéricos\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhD8F8a50Bma"
      },
      "source": [
        "O trecho a seguir define um pipeline genérico, apenas para os atributos categóricos.\n",
        "\n",
        "A etapa usando `MostFrequentImputer()` preenche valores faltando com o mais frequente dos valores daquele atributo. Já a etapa seguinte, usando `OneHotEncoder(sparse=False)` expande cada atributo que não é numérico para um conjunto de atributos binários. Esta precisa ser a última etapa desse _pipeline_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylLFaKFc0Bmb"
      },
      "source": [
        "# pipeline para atributos categóricos\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('imputer', MostFrequentImputer()),\n",
        "    ('encoder', OneHotEncoder(sparse=False)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSJQW3Iv0Bmb"
      },
      "source": [
        "A seguir usamos o recurso `ColumnTransformer` para aplicar determinados _pipelines_ para determinados atributos. Assim temos um _pipeline_ inteligente que processa os dados de uma só vez, mas executa operações diferentes conforme a natureza de cada atributo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pRbDV3w0Bmb"
      },
      "source": [
        "# pipeline combinando atributos numéricos com atributos categóricos\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    ('num', num_pipeline, ['NU_MEDIA_MT_2014', 'NU_MEDIA_RED_2014',\n",
        "                           'NU_MATRICULAS_2015', \n",
        "                           'NU_PARTICIPANTES_NEC_ESP_2015', 'NU_PARTICIPANTES_2015', 'NU_TAXA_PARTICIPACAO_2015',\n",
        "                           'PC_FORMACAO_DOCENTE_2015', 'NU_TAXA_PERMANENCIA_2015', 'NU_TAXA_APROVACAO_2015',\n",
        "                           'NU_TAXA_REPROVACAO_2015', 'NU_TAXA_ABANDONO_2015']),\n",
        "    ('cat', cat_pipeline, ['TP_DEPENDENCIA_ADM_ESCOLA_2015', 'TP_LOCALIZACAO_ESCOLA_2015', 'INSE_2015',\n",
        "                           'PORTE_ESCOLA_2015']),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HG4xNaW0Bmb"
      },
      "source": [
        "Enfim, processamos os features de treino e de teste, gerando os conjuntos prontos para o treinamento. Note que para os dados de treino usamos `.fit_transform()`, enquanto para os de teste apenas `.transform()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s9NBF8h0Bmc"
      },
      "source": [
        "# preprocessamento\n",
        "X_treino = full_pipeline.fit_transform(treino_features)\n",
        "X_teste  = full_pipeline.transform(teste_features)\n",
        "print(X_treino)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7HIaWiN0Bmc"
      },
      "source": [
        "Aqui vamos extrair somente os dados brutos dos rótulos, e colocar em `y_treino`, que é o formato esperado pelos algoritmos de Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXn-Edvy0Bmc"
      },
      "source": [
        "y_treino = treino_rotulos.values\n",
        "y_teste  = teste_rotulos.values\n",
        "print(y_treino)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SinN-zGS0Bmd"
      },
      "source": [
        "# Seleção do modelo\n",
        "\n",
        "Aqui selecionamos um modelo para o aprendizado, baseado em um dos possíveis algoritmos de regressão. \n",
        "\n",
        "Como estamos criando um modelo com duas saídas (_multioutput_), para regressores simples precisamos usar o recurso `MultiOutputRegressor`. Este cria internamente um modelo separado para cada saída, mas os processos de treino, validação, teste e predição continuam os mesmos.\n",
        "\n",
        "Já o modelo do tipo `RandomForestRegressor` é naturalmente capaz de gerar múltiplas saídas, então pode ser utilizado diretamente.\n",
        "\n",
        "**Ajuste:** Depois de medir o desempenho do modelo você pode habilitar outros algoritmos. Note que apenas um  comando deve estar ativo (a linha de criação do `classificador`).\n",
        "\n",
        "- Para o algoritmo `SVR` você pode mudar os hiperparâmetros `C` e `gamma='auto'`.\n",
        "\n",
        "- Para o algoritmo `SGDRegressor` você pode mudar o hiperparâmetro `eta0`.\n",
        "\n",
        "- Para o algoritmo `LinearRegression` não há hiperparâmetros a serem ajustados.\n",
        "\n",
        "- Para o algoritmo `RandomForestRegressor` você pode aumentar o parâmetro `n_estimators`, por exemplo para 10 ou 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccy7Yki60Bmd"
      },
      "source": [
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regressor = MultiOutputRegressor(SVR(C=1.0, gamma='scale'))\n",
        "\n",
        "#regressor = MultiOutputRegressor(SGDRegressor(random_state=42, learning_rate='constant', eta0=0.0001))\n",
        "\n",
        "#regressor = MultiOutputRegressor(LinearRegression())\n",
        "\n",
        "#regressor = RandomForestRegressor(random_state=42, n_estimators=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0LvnP9m0Bmd"
      },
      "source": [
        "# Treino e medida de desempenho\n",
        "\n",
        "Vamos treinar e avaliar o regressor fazendo a **validação cruzada** do conjunto de treino. O parâmetro `cv=3` indica o número de dobras (ou _folds_), que é o número de vezes em que o conjunto é repartido, treinado e mensurado.\n",
        "\n",
        "Como medida de desempenho vamos usar o erro absoluto médio. **Quanto menor esse erro, melhor.** Ele indica em média quantos pontos a mais ou menos as previsões das notas erram.\n",
        "\n",
        "Como a validação cruzada devolve várias medidas, guardadas na lista `scores`, calculamos e exibimos uma média aritmética simples dessas medidas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abpc0kQD0Bme"
      },
      "source": [
        "# validação cruzada\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "%time scores = cross_val_score(regressor, X_treino, y_treino, cv=3, scoring='neg_mean_absolute_error')\n",
        "print('scores: ' + ('{:.2f} ' * len(scores)).format(*(-scores)))\n",
        "print('média:  {:.2f}'.format(-scores.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZGPxajF0Bme"
      },
      "source": [
        "**Opcional:** Para melhorar o modelo existem diversas possibilidades de **ajuste** do modelo:\n",
        "\n",
        "- A ação mais direta é simplesmente testar outros algoritmos, como mostrado na seção \"Seleção do Modelo\".\n",
        "\n",
        "- Também é possível experimentar com os hiperparâmetros dos diversos algoritmos.\n",
        "\n",
        "- Outra possibilidade é reduzir o número de _features_, simplesmente retirando atributos numéricos e categóricos do _pipeline_ `full_pipeline` na seção \"Preprocessamento\".\n",
        "\n",
        "**Avançado**: Ainda é possível incluir mais _features_ do ano de 2014, o que deve ser feito na seção \"Reorganização dos dados\" e depois na seção \"Preprocessamento\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R6LOMBc0Bme"
      },
      "source": [
        "# Teste final do modelo\n",
        "\n",
        "Se você estiver satisfeito com a qualidade obtida na validação cruzada, então podemos fazer o teste final do modelo `regressor`.\n",
        "\n",
        "Note que o treinamento do modelo é feito de fato aqui, com a chamada de `.fit()`. A validação cruzada feita anteriormente gera modelos temporários para as medidas e os descarta, mas não deixa o modelo treinado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPTYOzWa0Bmf"
      },
      "source": [
        "# treinamento\n",
        "regressor.fit(X_treino, y_treino)\n",
        "\n",
        "# geração das previsões\n",
        "y_teste_pred = regressor.predict(X_teste)\n",
        "print(y_teste_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKg6wZJR0Bmf"
      },
      "source": [
        "Agora vamos avaliar o erro absoluto médio novamente, porém comparando o valores previstos com base nos dados de teste contra os rótulos reais para os mesmos dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx9jtRxE0Bmf"
      },
      "source": [
        "# medida de desempenho\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "score_teste = mean_absolute_error(y_teste, y_teste_pred)\n",
        "print('score teste: {:.2f}'.format(score_teste))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDpW8wbh0Bmg"
      },
      "source": [
        "Caso o modelo escolhido seja do tipo `RandomForestRegressor`, podemos inspecionar a importância aprendida para as features do conjunto, o que dá um _insight_ importante sobre os dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6DDCZxF0Bmg"
      },
      "source": [
        "# lista a importância das features\n",
        "if type(regressor) != RandomForestRegressor:\n",
        "    print('AVISO: este tipo de regressor não permite visualizar a importância das features')\n",
        "else:\n",
        "    # features listadas por ordem crescente de importância\n",
        "    for score, name in sorted(zip(regressor.feature_importances_, treino_features.columns)):\n",
        "        print('{:06.2%}'.format(score), name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjhJpU0B0Bmh"
      },
      "source": [
        "# Criando um modelo de rede neural\n",
        "\n",
        "Aqui vamos criar uma rede neural de regressão, usando um modelo (ou arquitetura) do tipo sequencial. O modelo sequencial corresponde ao tipo mais simples de rede neural, onde uma sequência de camadas de neurônios é empilhada uma em cima da outra.\n",
        "\n",
        "Para este tipo específico de tarefa de regressão, não selecionamos nenhuma função de ativação para a camada de saída. Ou seja, basta deixar os dados \"brutos\" sairem da rede neural.\n",
        "\n",
        "Além disso, como queremos gerar a previsão para dois rótulos distintos, a camada de saída precisa ter **duas saídas**.\n",
        "\n",
        "Observe os demais parâmetros para o processo de treinamento:\n",
        "\n",
        "- O parâmetro `n_splits=2` define o número de quebras do conjunto de treinamento para a validação cruzada.\n",
        "\n",
        "- A arquitetura da rede pode ser modificada, adicionando novas camadas ocultas ou mudando o númere de neurônio das mesmas.\n",
        "\n",
        "- A função de perda é dada por `loss='mean_absolute_error'`, e precisa ser a mesma utilizada anteriormente em outros modelos, para que possamos comparar seu desempenho.\n",
        "\n",
        "- A taxa de aprendizado é dada pelo hiperparâmetro `lr=0.01`, que também pode ser experimentada.\n",
        "\n",
        "- É possivel usar a estratégia de _early stopping_ descomentando a linha `callbacks=[keras.callbacks.EarlyStopping(patience=5)],`.\n",
        "\n",
        "- Pode-se ainda mudar o número de épocas com o hiperparâmetro `epochs=10` (experimente com valores maiores)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFoNXV390Bmh"
      },
      "source": [
        "# comandos para 'zerar' a biblioteca Keras e definir as sementes aleatórias\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# controle da validação cruzada\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(random_state=42, shuffle=True, n_splits=2) # número de folds\n",
        "scores = []\n",
        "for fold_treino, fold_valid in kfold.split(X_treino, y_treino):\n",
        "    # especificação do modelo\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Dense(30, activation='relu', input_shape=[X_treino.shape[1]]),\n",
        "      # keras.layers.Dense(10, activation='relu'),\n",
        "        keras.layers.Dense(2, activation=None)\n",
        "    ])\n",
        "\n",
        "    # especificação da função de perda e do algoritmo de otimização\n",
        "    model.compile(loss='mean_absolute_error', optimizer=keras.optimizers.SGD(lr=0.01)) # taxa de aprendizado\n",
        "\n",
        "    # treinamento\n",
        "    print('------------------------------------------= FOLD =------------------------------------------')\n",
        "    history = model.fit(X_treino[fold_treino], y_treino[fold_treino], epochs=10, # número de épocas\n",
        "                        #callbacks=[keras.callbacks.EarlyStopping(patience=5)],\n",
        "                        validation_data=(X_treino[fold_valid], y_treino[fold_valid]))\n",
        "    scores.append(history.history['loss'][-1])\n",
        "    \n",
        "    # exibição das funções de perda de treino e de validação, para cada época (eixo horizontal)\n",
        "    pd.DataFrame(history.history).iloc[2:].plot(figsize=(10, 4))\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "print('scores: ' + ('{:.2f} ' * len(scores)).format(*scores))\n",
        "print('média:  {:.2f}'.format(np.mean(scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOQQyK2X0Bmi"
      },
      "source": [
        "# Geração de previsões e teste final do modelo de rede neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg6J8LtY0Bmi"
      },
      "source": [
        "# previsões computadas para três instâncias de teste\n",
        "y_predi = model.predict(tf.constant(X_teste[:3]))\n",
        "print('previsões: ', y_predi[0].round(2), y_predi[1].round(2), y_predi[2].round(2))\n",
        "print('rótulos:   ', y_teste[0].round(2), y_teste[1].round(2), y_teste[2].round(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hT9gDRE0Bmi"
      },
      "source": [
        "# avaliação com conjunto de teste\n",
        "score_teste = model.evaluate(X_teste, y_teste)\n",
        "print('score teste: {:.2f}'.format(score_teste))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}